{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677c52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil\n",
    "from Env.market_env import FTPEnv\n",
    "from Env.recorder import StrategyRecorder\n",
    "from models.model import TradingPolicy\n",
    "from Env.benchmarks import FOICPolicy, GLFTPolicy\n",
    "from models.GateUnits import SGU1, SGU2\n",
    "from pipeline.agent_trainer import load_signals_bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dba778",
   "metadata": {},
   "source": [
    "In this notebook, we run backtest for four components:\n",
    "\n",
    "- `DRL MM Agent with adversarial training (DRL1)`\n",
    "- `DRL MM Agent (DRL2)`\n",
    "- `GLFT`\n",
    "- `FOIC`\n",
    "\n",
    "on the same OOS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a81c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_drl_backtest(symbol, method_name, weight_path, bundle, phi, fee_rate, train_stats):\n",
    "    s1, s2, mid, ask, bid, b_max, s_min = bundle \n",
    "\n",
    "    policy = TradingPolicy()\n",
    "    if os.path.exists(weight_path):\n",
    "        policy.load_state_dict(torch.load(weight_path, weights_only=True))\n",
    "        policy.eval()\n",
    "    else:\n",
    "        print(f\"Warning: Weights not found at {weight_path}\")\n",
    "        return None\n",
    "    \n",
    "    env = FTPEnv(phi=phi, tick_size=0.001, fee_rate=fee_rate) \n",
    "    recorder = StrategyRecorder()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t in range(len(mid)):\n",
    "            n_s = torch.tensor([[(s1[t]-train_stats['s1_m'])/train_stats['s1_s'], \n",
    "                                 (s2[t]-train_stats['s2_m'])/train_stats['s2_s'], \n",
    "                                 env.inventory/2.0]], dtype=torch.float32)\n",
    "            \n",
    "            raw_act = policy.forward(n_s).squeeze().cpu().numpy()\n",
    "            scaled_act = np.round(raw_act * 5.0).astype(int) \n",
    "\n",
    "            reward, info = env.step(scaled_act, mid[t], ask[t], bid[t], b_max[t], s_min[t])\n",
    "\n",
    "            record_data = {\n",
    "                'step': t,\n",
    "                'mid': mid[t],\n",
    "                'ask': ask[t],\n",
    "                'bid': bid[t],\n",
    "                'off_a': scaled_act[0], \n",
    "                'off_b': scaled_act[1], \n",
    "                'action': scaled_act,\n",
    "                'reward': reward,\n",
    "                'inventory': env.inventory,\n",
    "                'cash': env.cash,\n",
    "                'fee_paid': info.get('fee_paid', 0.0), \n",
    "                's1_pred': s1[t],\n",
    "                's2_pred': s2[t]\n",
    "            }\n",
    "            record_data.update(info)\n",
    "            recorder.data.append(record_data)\n",
    "            \n",
    "    df = recorder.to_dataframe() \n",
    "    save_path = f\"output/{symbol}/{method_name}/backtest_{phi}.parquet\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_parquet(save_path, index=False)\n",
    "    print(f\"Success: {method_name} backtest completed.\")\n",
    "    return df\n",
    "\n",
    "def run_benchmark_and_save(strategy_name, policy, bundle, phi_param, fee_rate, save_dir, train_stats):\n",
    "    s1, s2, mid, ask, bid, b_max, s_min = bundle\n",
    "    env = FTPEnv(phi=phi_param, tick_size=0.001, fee_rate=fee_rate)\n",
    "    recorder = StrategyRecorder()\n",
    "\n",
    "    for t in range(len(mid)):\n",
    "        raw_offsets = policy.get_action(env.inventory)\n",
    "        mid_p = (ask[t] + bid[t]) / 2.0\n",
    "\n",
    "        if strategy_name == 'glft':\n",
    "            off_a = ((mid_p + raw_offsets[0]) - ask[t]) / 0.001\n",
    "            off_b = (bid[t] - (mid_p - raw_offsets[1])) / 0.001\n",
    "            action = np.round([off_a, off_b]).astype(int)\n",
    "        else:\n",
    "            action = np.round(raw_offsets).astype(int)\n",
    "        \n",
    "        reward, info = env.step(action, mid[t], ask[t], bid[t], b_max[t], s_min[t])\n",
    "\n",
    "        record_data = {\n",
    "            'step': t, 'mid': mid[t], 'ask': ask[t], 'bid': bid[t],\n",
    "            'off_a': action[0], 'off_b': action[1], \n",
    "            'action': action, 'reward': reward, 'inventory': env.inventory, 'cash': env.cash,\n",
    "            'fee_paid': info.get('fee_paid', 0.0),\n",
    "            's1_pred': s1[t], 's2_pred': s2[t]\n",
    "        }\n",
    "        record_data.update(info)\n",
    "        recorder.data.append(record_data)\n",
    "        \n",
    "    df = recorder.to_dataframe()\n",
    "    save_path = f\"{save_dir}/backtest_{phi_param}.parquet\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df.to_parquet(save_path, index=False)\n",
    "    print(f\"Success: {strategy_name} benchmark completed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53966e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"510300\"\n",
    "phi_val = 0.0001\n",
    "fee_rate = 0.0000\n",
    "sgu_train_range = (20240401, 20240528)\n",
    "base_path = os.path.abspath(\"checkpoints\") \n",
    "checkpoint_dir = os.path.join(base_path, symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea5737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SGU1 loaded successfully.\n",
      "SGU2 model loaded from d:\\UW\\Course\\2026 WINTER\\522_trade_sys\\replication\\checkpoints\\510300\\sgu2_20240401_20240528.pth and set to eval mode.\n",
      ">>> SGU2 (LSTM) loaded successfully.\n",
      ">>> Scaler loaded. S3 evaluation starts after: 20240528\n"
     ]
    }
   ],
   "source": [
    "# loading signals and scaler\n",
    "m1 = SGU1()\n",
    "s1_raw_path = os.path.join(checkpoint_dir, f\"sgu1_{sgu_train_range[0]}_{sgu_train_range[1]}.json\")\n",
    "tmp_s1_path = \"tmp_sgu1_model.json\"\n",
    "shutil.copy2(s1_raw_path, tmp_s1_path)\n",
    "try:\n",
    "    m1.load(tmp_s1_path)\n",
    "    print(\">>> SGU1 loaded successfully.\")\n",
    "finally:\n",
    "    if os.path.exists(tmp_s1_path):\n",
    "        os.remove(tmp_s1_path)\n",
    "\n",
    "m2 = SGU2(input_size=1, hidden_size=10)\n",
    "s2_path = os.path.join(checkpoint_dir, f\"sgu2_{sgu_train_range[0]}_{sgu_train_range[1]}.pth\")\n",
    "m2.load(s2_path)\n",
    "print(\">>> SGU2 (LSTM) loaded successfully.\")\n",
    "\n",
    "scaler_path = os.path.join(checkpoint_dir, f\"sgu2_scaler_{sgu_train_range[0]}_{sgu_train_range[1]}.pkl\")\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "    \n",
    "s3_start_date = sgu_train_range[1]\n",
    "print(f\">>> Scaler loaded. S3 evaluation starts after: {s3_start_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e084401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> S3 Data Pool: 22 days | Train-subset: 15 | Test-subset: 4\n",
      "Bundling S3-Train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundling S3-Test data (Blind Test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "snap_dir = f'data/{symbol}/snap'\n",
    "all_dates = sorted([f[:8] for f in os.listdir(snap_dir) if f.endswith('.parquet')])\n",
    "s3_dates = [d for d in all_dates if int(d) > s3_start_date]\n",
    "n_s3 = len(s3_dates)\n",
    "if n_s3 < 5:\n",
    "    raise ValueError(f\"Insufficient S3 data after {s3_start_date}.\")\n",
    "\n",
    "train_idx = int(n_s3 * 0.70)\n",
    "val_idx = int(n_s3 * 0.85)\n",
    "\n",
    "train_dates = s3_dates[:train_idx]\n",
    "test_dates = s3_dates[val_idx:]\n",
    "\n",
    "print(f\">>> S3 Data Pool: {n_s3} days | Train-subset: {len(train_dates)} | Test-subset: {len(test_dates)}\")\n",
    "\n",
    "print(\"Bundling S3-Train data...\")\n",
    "train_bundle = load_signals_bundle(symbol, train_dates, m1, m2, scaler)\n",
    "print(\"Bundling S3-Test data (Blind Test)...\")\n",
    "s3_bundle = load_signals_bundle(symbol, test_dates, m1, m2, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3469d30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Normalization stats locked: {'s1_m': 2.0911791, 's1_s': 0.3246540139184723, 's2_m': 0.019486755, 's2_s': 0.4570208797918091}\n"
     ]
    }
   ],
   "source": [
    "s1_t, s2_t = train_bundle[0], train_bundle[1]\n",
    "\n",
    "train_stats = {\n",
    "    's1_m': np.mean(s1_t), \n",
    "    's1_s': np.std(s1_t) + 1e-9,\n",
    "    's2_m': np.mean(s2_t), \n",
    "    's2_s': np.std(s2_t) + 1e-9\n",
    "}\n",
    "\n",
    "print(f\">>> Normalization stats locked: {train_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e9597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: drl backtest completed.\n",
      "Success: arl backtest completed.\n",
      "Success: glft benchmark completed.\n",
      "Success: foic benchmark completed.\n",
      "\n",
      ">>> All backtests completed. Parquet datasets generated in 'output/' directory.\n"
     ]
    }
   ],
   "source": [
    "path_drl = os.path.join(checkpoint_dir, f\"without_adv/agent_best_val_{phi_val}.pth\")\n",
    "path_arl = os.path.join(checkpoint_dir, f\"with_adv/agent_best_val_{phi_val}.pth\")\n",
    "# DRL\n",
    "run_drl_backtest(symbol, \"drl\", path_drl, s3_bundle, phi_val, fee_rate, train_stats)\n",
    "# Adv DRL\n",
    "run_drl_backtest(symbol, \"arl\", path_arl, s3_bundle, phi_val, fee_rate, train_stats)\n",
    "# GLFT\n",
    "glft_p = GLFTPolicy(gamma=0.001, kappa=100, A=0.1, sigma=0.01)\n",
    "run_benchmark_and_save(\"glft\", glft_p, s3_bundle, phi_val, fee_rate, f\"output/{symbol}/glft\", train_stats)\n",
    "# FOIC\n",
    "foic_p = FOICPolicy(offset_a=0, offset_b=0)\n",
    "run_benchmark_and_save(\"foic\", foic_p, s3_bundle, phi_val, fee_rate, f\"output/{symbol}/foic\", train_stats)\n",
    "\n",
    "print(\"\\n>>> All backtests completed. Parquet datasets generated in 'output/' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
